import csv, datetime, requests, zipfile, pathlib, os
import ak_scraper
import al_scraper
import ar_scraper
import ca_scraper
import co_scraper
import ct_scraper
import de_scraper
import fl_scraper
import ga_scraper
import id_scraper
import in_scraper
import il_scraper
import la_scraper
import mi_scraper
import mn_scraper
import ms_scraper
import mo_scraper
import mt_scraper
import ne_scraper
import nv_scraper
import nm_scraper
import nyc_scraper
import nc_scraper
import ok_scraper
import oh_scraper
import sc_scraper
import tn_scraper
import tx_scraper
import va_scraper
import vt_scraper
import wi_scraper

def installEdgeDriver():

    driver_path = pathlib.Path("msedgedriver.exe")
    if driver_path.is_file():
        pass
    else:
        response = requests.get('https://msedgedriver.azureedge.net/84.0.524.0/edgedriver_win64.zip', stream=True)

        save_path = pathlib.Path.cwd().joinpath('temp', 'edgedriver_win64.zip')
        with open(save_path, 'wb') as fd:
            for chunk in response.iter_content(chunk_size=128):
                fd.write(chunk)

        with zipfile.ZipFile(save_path, 'r') as zipObj:
            zipObj.extract('msedgedriver.exe', path=None, pwd=None)

def installGeckoDriver():
    driver_path = pathlib.Path("geckodriver.exe")
    if driver_path.is_file():
        pass
    else:
        response = requests.get('https://github.com/mozilla/geckodriver/releases/download/v0.27.0/geckodriver-v0.27.0-win64.zip', stream=True)

        save_path = pathlib.Path.cwd().joinpath('temp', 'geckodriver-v0.27.0-win64.zip')
        with open(save_path, 'wb') as fd:
            for chunk in response.iter_content(chunk_size=128):
                fd.write(chunk)

        with zipfile.ZipFile(save_path, 'r') as zipObj:
            zipObj.extract('geckodriver.exe', path=None, pwd=None)

def main():

    installEdgeDriver()
    installGeckoDriver()

    reports = []

    scrapers = []
    scrapers.append(ak_scraper)
    scrapers.append(al_scraper)
    scrapers.append(ar_scraper)
    scrapers.append(ca_scraper)
    scrapers.append(co_scraper)
    scrapers.append(ct_scraper)
    scrapers.append(de_scraper)
    scrapers.append(fl_scraper)
    scrapers.append(ga_scraper)
    scrapers.append(id_scraper)
    scrapers.append(in_scraper)
    scrapers.append(il_scraper)
    scrapers.append(la_scraper)
    scrapers.append(mi_scraper)
    scrapers.append(mn_scraper)
    scrapers.append(ms_scraper)
    scrapers.append(mo_scraper)
    scrapers.append(mt_scraper)
    scrapers.append(ne_scraper)
    scrapers.append(nv_scraper)
    scrapers.append(nm_scraper)
    scrapers.append(nyc_scraper)
    scrapers.append(nc_scraper)
    scrapers.append(oh_scraper)
    scrapers.append(ok_scraper)
    scrapers.append(sc_scraper)
    scrapers.append(tn_scraper)
    scrapers.append(tx_scraper)
    scrapers.append(va_scraper)
    scrapers.append(vt_scraper)
    scrapers.append(wi_scraper)


    for scraper in scrapers:
        print('Starting scrape for' , scraper.STATE, '...')
        report = scraper.scraper()
        print(scraper.STATE, ' report generated at ', report.timestamp)
        reports.append(report)

    counties = []
    for report in reports:
        for county in report.counties:
            counties.append(county)

    # The following section writes the final CSV output containing all counties for all states

    # First, create an /output folder that will store the final .csv containing all the counties
    outputpath = 'output' 
    if not os.path.exists(outputpath):
        os.makedirs(outputpath)

    # Second, determine the filename to use - we'll include a timestamp in the filename itself that explains when the file was generated by our Python 3 code
    filename = datetime.datetime.now().strftime("%Y-%m-%d_%H%M%S") + '_all_counties.csv'
    filepath = pathlib.Path.cwd().joinpath('output', filename)

    # Third, do the actual writing of the state reports to a CSV file
    with open(filepath, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)

        for county in counties:
            writer.writerow([ county.state, county.county, county.confirmed, county.deaths, county.hospitalizations, county.timestamp ])

main()